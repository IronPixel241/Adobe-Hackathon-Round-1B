# ðŸš€ Adobe Hackathon 2025 â€“ Persona-Driven Document Intelligence

This project was developed for **Round 1B** of the [Adobe â€œConnecting the Dotsâ€ Hackathon](https://github.com/jhaaj08/Adobe-India-Hackathon25). It transforms static PDF documents into an intelligent assistant tailored to specific personas and tasks.

---

## ðŸ“Œ Problem Statement

Given a **collection of related PDFs**, a **persona** (e.g., Researcher, Student, Analyst), and a **specific job-to-be-done**, the system intelligently:
- Extracts and segments the documents into meaningful sections
- Ranks sections based on semantic relevance
- Applies lightweight LLM verification to ensure alignment with the task
- Outputs structured JSON with ranked sections and refined content

---

## âœ¨ Key Features

### ðŸ§  Hybrid AI Architecture
- **Vector Embedding (Fast Retrieval)**: Uses `all-MiniLM-L6-v2` (â‰¤90MB) to perform semantic search across all document sections.
- **LLM Verification (Deep Understanding)**: Uses `google/flan-t5-small` (â‰ˆ100MB) as a fast, local verifier for top 20 candidates only.

### âš¡ Performance-Aware Pipeline
- Smartly balances speed and intelligence within the strict **60-second** offline runtime limit.
- Applies LLM only to most promising sections to save time and compute.

### ðŸ“„ Robust Section Segmentation
- Dynamically segments PDFs into logical sections using:
  - Title case detection
  - Heuristics on line length, indentation, and structure
  - No reliance on font size or brittle PDF rules

---

## ðŸ› ï¸ Tech Stack

| Component              | Description                                  |
|------------------------|----------------------------------------------|
| ðŸ“š Libraries           | `PyMuPDF`, `sentence-transformers`, `NumPy`, `torch`, `transformers` |
| ðŸ” Embedding Model     | `all-MiniLM-L6-v2` (via sentence-transformers) |
| ðŸ¤– Lightweight LLM     | `google/flan-t5-small` (via HuggingFace Transformers) |
| ðŸ³ Containerization    | Docker (CPU-only, offline, amd64-compatible)  |

---

## ðŸ“‚ Directory Structure

```
â”œâ”€â”€ local_input/ 
â”‚   â””â”€â”€ input.json          # place the input.json file here
â”œâ”€â”€ local_output/           # Results (JSON) will be generated here
â”œâ”€â”€ src/
â”‚   â””â”€â”€ init.py             # intialization
â”‚   â””â”€â”€ main.py             # Pipeline orchestration
â”œâ”€â”€ Dockerfile              # Dockerfile to containerize the solution
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ download_models.py      # locally caches the model while running docker build (no network usage during docker run)
â””â”€â”€ README.md               # (You're reading it!)
```

---

## ðŸ§ª How It Works

### Step-by-Step Approach:

1. **Section Extraction**
   - All PDFs in the `input/` folder are parsed using `PyMuPDF`.
   - A custom heuristic algorithm splits text into titles, sections, and subsections.

2. **Semantic Ranking**
   - Persona and job-to-be-done are embedded into vectors.
   - Each sectionâ€™s title and content is vectorized and compared using **cosine similarity**.

3. **LLM Verification**
   - Top 20 semantically relevant sections are passed through `flan-t5-small`.
   - LLM ensures they logically fit the personaâ€™s needs (e.g., "Is this relevant for a Chemistry student preparing for kinetics?").

4. **Output Generation**
   - A structured JSON is written to the `output/` directory in the required format (matching `challenge1b_output.json`).

---

## ðŸš€ Quick Start

### ðŸ³ Build Docker Image

```bash
docker build -t persona-doc-intel:1b .
```

### â–¶ï¸ Run the Container

```bash
docker run --rm   -v "$(pwd)/input:/app/input"   -v "$(pwd)/output:/app/output"   --network none   persona-doc-intel:1b
```

> ðŸ“Œ This will generate `result.json` or `{filename}.json` inside the `output/` folder.

---

## ðŸ“¥ Input Format

**input/input.json** (example):

```json
{
  "persona": "Undergraduate Chemistry Student",
  "job": "Identify key concepts and mechanisms for exam preparation on reaction kinetics"
}
```

**input/** also contains PDFs:
```
input/
â”œâ”€â”€ input.json
â”œâ”€â”€ Organic_Chemistry_Chapter1.pdf
â”œâ”€â”€ Organic_Chemistry_Chapter2.pdf
â””â”€â”€ ...
```

---

## ðŸ“¤ Output Format

```json
{
  "metadata": {
    "documents": ["Organic_Chemistry_Chapter1.pdf", ...],
    "persona": "Undergraduate Chemistry Student",
    "job": "Identify key concepts and mechanisms for exam preparation on reaction kinetics",
    "timestamp": "2025-07-27T17:35:10Z"
  },
  "extracted_sections": [
    {
      "document": "Organic_Chemistry_Chapter1.pdf",
      "page_number": 5,
      "section_title": "Reaction Kinetics: Overview",
      "importance_rank": 1
    }
    ...
  ],
  "sub_section_analysis": [
    {
      "document": "Organic_Chemistry_Chapter1.pdf",
      "refined_text": "This section explains the rate-determining steps...",
      "page_number": 5
    }
  ]
}
```

---

## ðŸ§¾ Constraints Met

| Constraint               | Status       |
|--------------------------|--------------|
| â±ï¸ Execution Time        | â‰¤ 60 sec     |
| ðŸ“¦ Model Size            | â‰¤ 1GB        |
| âŒ No Internet Required  | âœ… Fully offline |
| ðŸ’» CPU Only              | âœ… Supported |
| ðŸ”„ Multidocument Support | âœ… 3â€“10 PDFs |

---

## ðŸ“š Reference

- [Sentence-Transformers](https://www.sbert.net/)
- [Flan-T5 Small on HuggingFace](https://huggingface.co/google/flan-t5-small)
- Adobe Challenge Docs: [PDF Brief](https://github.com/jhaaj08/Adobe-India-Hackathon25)

---

## ðŸ Final Notes

> This solution is designed to generalize well across different domains (academic, financial, educational, etc.).  
> All models are local and efficient, making the system fully compliant with Adobeâ€™s hackathon constraints.
